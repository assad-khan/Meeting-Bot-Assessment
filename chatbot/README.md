# ğŸ§  Meeting Bot - AI Transcript Assistant

An AI-powered assistant that processes meeting transcripts and allows users to chat with it to get summaries, decisions, action items, participants, and follow-up contextual answers. The system supports session-level memory, prompt intent routing, and semantic search to intelligently handle user queries.

---

## ğŸ“Œ Features

* ğŸ“„ **Transcript Analysis**: Vector search and semantic retrieval of uploaded transcripts.
* ğŸ” **Prompt Routing**: Handles summaries, participants, tasks, and general follow-ups.
* ğŸ§  **Context-Aware Responses**: Maintains session memory for coherent conversations.
* ğŸ”­ **Tracing and Logging**: Logs conversations, intents, and system behavior.
* ğŸ— **Modular Design**: Clean architecture for extensibility and maintenance.

---

## ğŸ¤© Modules Overview

### `server.py`

* Flask backend with two main endpoints:

  * `POST /upload`: Uploads and stores meeting transcript per session.
  * `POST /chat`: Handles chat messages and routes them to the AI engine.
* Manages sessions and stores in-memory chat history.

### `chatbot/engine.py`

* Core AI engine:

  * Transcript summarization
  * Intent classification and routing
  * Vector search using FAISS
  * Action item and participant extraction
  * Conversational memory
* Uses:

  * `LangChain` for LLM workflows
  * `FAISS` for fast vector similarity search
  * `ConversationBufferMemory` for memory tracking

---

## ğŸ” Prompt Routing Logic

Prompts are classified using keyword-based logic:

| Intent         | Trigger Keywords                             | Action                           |
| -------------- | -------------------------------------------- | -------------------------------- |
| `summary`      | "summarize", "summary", "recap"              | `summarize_transcript()`         |
| `participants` | "participants", "attendees", "who attended"  | `extract_participants()`         |
| `actions`      | "action items", "tasks", "to-do", "assigned" | `extract_action_items()`         |
| `chat`         | Anything else                                | `ConversationalRetrievalChain()` |

Handled using a `classify_intent()` function that routes queries accordingly.

---

## ğŸ§  System Architecture

### ğŸ–¼ï¸ Architecture Diagram (Text Format)

```
[Frontend UI]
     â†“
[Flask Backend - server.py]
     â†“
[Chat Engine - engine.py]
â”œâ”€â”€ Transcript Summary        â†’ LLMChain
â”œâ”€â”€ Participant Extraction    â†’ LLMChain
â”œâ”€â”€ Action Item Extraction    â†’ LLMChain
â””â”€â”€ Conversational QA         â†’ ConversationalRetrievalChain
    â”œâ”€â”€ Memory                â†’ ConversationBufferMemory
    â””â”€â”€ Retrieval             â†’ FAISS Vector Store
```

---

## âš™ï¸ Workflow

1. **Upload Transcript**: Sent via `/upload`, stored in session, and embedded for retrieval.
2. **User Query**: Sent via `/chat`, classified by intent.
3. **Response Generation**:

   * Structured prompts â†’ routed to specific LLMChains.
   * General questions â†’ handled by retriever + memory chain.
4. **Session Memory**: Maintains conversation history.
5. **Logging**: All interactions are logged for observability and debugging.

---

## ğŸ“‚ Project Structure

```
meeting-bot/
â”œâ”€â”€ chatbot/
â”‚   â””â”€â”€ engine.py         # AI engine logic
â”œâ”€â”€ server.py             # Flask API server
â”œâ”€â”€ frontend/             # Chat UI
â”‚   â””â”€â”€ index.html         
â”‚   â””â”€â”€ scripts.js        
â”‚   â””â”€â”€ style.css       
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation
```

---

## âœ… Installation

Install required Python packages:

```bash
pip install -r requirements.txt
```

---

## ğŸ” Environment Setup

Add your OpenAI API key inside `.env`:

```env
OPENAI_API_KEY="your_openai_api_key_here"
```

---

## ğŸ§ª Sample Prompts to Try

* "Summarize the meeting"
* "Who participated?"
* "What are the action items?"
* "What decisions were made?"
* "What did I just ask you?"
